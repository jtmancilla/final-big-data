PIG

## creamos hdfs.

kite-dataset create dataset:hdfs:/user/itam/datasets/gdelt --schema data/gdelt.avsc

kite-dataset csv-import data/20130412.export.CSV dataset:hdfs:/user/itam/datasets/gdelt --delimiter "\t"

## entramos grunt

pig -useHCatalog

### CARGAMOS avro

gdelt = LOAD 'datasets/gdelt' USING org.apache.pig.piggybank.storage.avro.AvroStorage();

### visualizando la tabla de gdelt

head = LIMIT gdelt 5;
DUMP head; 

#guardamos TEORICO. NO se ha probado.
store head into '/user/itam/data/head' using PigStorage('\t','-schema');


##########################################################
### visualizamos Actores distintos.

Actor1Name = DISTINCT (FOREACH gdelt GENERATE Actor1Name);
DUMP Actor1Name;


### Visualizamos los pa√≠ses

gdelt2 = FILTER gdelt by ActionGeo_CountryCode != '';
country = DISTINCT (FOREACH gdelt2 GENERATE ActionGeo_CountryCode);
DUMP country;


### Contamos los eventos por actor principal pais.

gdelt_grp = GROUP gdelt by Actor1CountryCode;
country = FOREACH gdelt GENERATE Actor1CountryCode;
gdelt_cnt = FOREACH gdelt_grp GENERATE GROUP AS country, COUNT(gdelt) as count;
DUMP gdelt_cnt;


### Contar el total de lineas
### SELECT COUNT(*) FROM gdelt;

gdelt_grp = GROUP gdelt all;
gdelt_cnt = FOREACH gdelt_grp GENERATE COUNT(gdelt);
DUMP gdelt_cnt;

### Contar los distitntos EventCode  (clasificacion del evento)
### SELECT COUNT(DISTINCT EventCode) FROM gdelt;

event = DISTINCT(FOREACH gdelt GENERATE EventCode);
event_grp = GROUP event all;
event_cnt = FOREACH event_grp GENERATE COUNT(event);
DUMP event_cnt;





